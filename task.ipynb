{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task: Data Classification in Financial Domain\n",
    "=======\n",
    "\n",
    "\n",
    "This notebook is dedicated to a classification problem in the financial domain. We use a dataset (available in the current directory as `moro14_synth2.csv`), which is synthesized from the [bank telemarketing dataset](https://www.researchgate.net/publication/260805594_A_Data-Driven_Approach_to_Predict_the_Success_of_Bank_Telemarketing). The detailed description of the included variables (columns) can be found in [UCI repository](https://archive.ics.uci.edu/ml/datasets/bank+marketing).\n",
    "\n",
    "The following cells contain code snippets to build a classification pipeline using the above dataset. The main task is to predict the variable `y`, based on the data at hand.\n",
    "\n",
    "We ask for the candidate to:\n",
    "\n",
    "- investigate and justify pre-processing steps to be performed on the data;\n",
    "- correct the implementation (which contains various deliberately problematic aspects) into a proper cross-validation procedure;\n",
    "- choose and justify evaluation strategies for the given problem.\n",
    "\n",
    "\n",
    "## Task 1: Data Analysis & Pre-processing\n",
    "\n",
    "It may be wise to pre-process the data. Please conduct an analysis to investigate what pre-processing you might want to do.\n",
    "\n",
    "First, load the data using the following code cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# for reproducibility\n",
    "np.random.seed(2021)\n",
    "\n",
    "# load data\n",
    "df = pd.read_csv('moro14_synth2.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the provided line of code loads the data, spend a (couple of) cells and Markdown blocks to explore the data. Report and discuss any interesting findings from the data. If there exist any concerns to be addressed, also discuss them accordingly.\n",
    "\n",
    "[NOTE]: Please assume you only have the current dataset at hand, so do not assume prior distributional knowledge from the original bank telemarketing dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore the dataset `df` and elaborate on your exploration.\n",
    "# Feel free to use as many Markdown comment blocks and code blocks as you want, and feel free to add visualizations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next code cell, an empty function spec is given, for running pre-processing on the data before further classification will be performed. Please complete the function with any pre-processing steps you would like to take, and explain the details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "\n",
    "def pre_processing(df_: pd.DataFrame) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"Pre-processing step for classification task\n",
    "    \n",
    "    This function takes the data frame loaded from above and returns \n",
    "    a tuple of the NumPy array. The tuple's first element is the independent variables,\n",
    "    or feature vectors, having a shape of (N, d) where N is the number of observations \n",
    "    and d is the number of variables (or columns). The tuple's second element is that\n",
    "    the vector represents the dependent variable or label with the shape in (N,).\n",
    "    \n",
    "    Finalize this function to pre-process the data frame to be fit in the output spec.\n",
    "    Beyond the mechanical conversion between input data-type and output data-type,\n",
    "    apply any content-wise pre-processing that is necessary.\n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now call this function to pre-process the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple ``execution`` lines\n",
    "X, y = pre_processing(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Classification & Model Selection\n",
    "\n",
    "We now will proceed to the training-model selection steps of the classification task. In particular, we consider a range of classification models:\n",
    "\n",
    "- Gaussian Naive Bayes Classifier\n",
    "- Logistic Regression\n",
    "- Quadratic Discriminant Analysis\n",
    "- Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "clfs = {\n",
    "    'LR': LogisticRegression(),\n",
    "    'QDA': QuadraticDiscriminantAnalysis(),\n",
    "    'GNB': GaussianNB(),\n",
    "    'DT': DecisionTreeClassifier()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are interested in selecting the better model from these candidates through a cross-validation procedure.\n",
    "\n",
    "We provide some basic code below, but this code is (deliberately) problematic. Please improve the procedure; feel free to fully modify the cells, and to include any further intermediate processing steps you find necessary.\n",
    "\n",
    "Furthermore, we have not said anything about evaluation. Please propose and implement a proper evaluation procedure, such that a model can be selected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples, n_features = X.shape\n",
    "\n",
    "# split the dataset into train / test\n",
    "rnd_idx = np.random.permutation(n_samples)\n",
    "bound = int(n_samples / 2)\n",
    "\n",
    "x_train = X[rnd_idx[:bound]]\n",
    "y_train = y[rnd_idx[:bound]]\n",
    "x_test = X[rnd_idx[bound:]]\n",
    "y_test = y[rnd_idx[bound:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here all classifiers are trained with the train dataset split\n",
    "# [note] if there's warning or error, try to fix it or try to discuss about it\n",
    "for name, clf in clfs.items():\n",
    "    clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how would you evaluate, and jusitfy a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion of evaluation results\n",
    "\n",
    "Could you find any irregular/unexpected/interesting behavior? Write a cell to evaluate them and discuss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# answer go here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
